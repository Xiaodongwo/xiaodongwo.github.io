<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Xiaodong Wang</title>
    <link>https://xiaodongwo.github.io/</link>
      <atom:link href="https://xiaodongwo.github.io/index.xml" rel="self" type="application/rss+xml" />
    <description>Xiaodong Wang</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Sun, 25 Dec 2022 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://xiaodongwo.github.io/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_3.png</url>
      <title>Xiaodong Wang</title>
      <link>https://xiaodongwo.github.io/</link>
    </image>
    
    <item>
      <title>Intelligent Algorithms for Wavefront Shaping</title>
      <link>https://xiaodongwo.github.io/projects/1st_project/</link>
      <pubDate>Wed, 08 Sep 2021 19:44:03 +0800</pubDate>
      <guid>https://xiaodongwo.github.io/projects/1st_project/</guid>
      <description>&lt;p&gt;Focusing or imaging through scattering media is still a big challenge because inhomogeneous media scatter incoming photons for focusing and outgoing photons for observation. Various approachs have been proposed to tackle the scattering issues. One can measure the transmission matrix of the scattering media in advance in order to compensate the scattering effect, yet this method relies heavily on the characterization of scattering media, making it time-comsuming and not general enough. Wavefront shaping is an optimization-algorithm based method that exploit no prior information of scattering media. Most off-the-self optimization algorithms focus on genetic algorithm and its variants. Genetic algorithm is one of the most powerful evolutionary algorithms that shares great popularity among industries. Here in this project we intent to compare the optimization performance in wavefront shaping using different evolutionary algorithms.&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-figure-1-wavefront-shaping-by-genetic-algorithm&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;screen reader text&#34; srcset=&#34;
               /media/GA_1D_WFS_hufb84d618928132b13f235d1b5f732ff7_672866_5d0a98fd17bdd76708e6e4fb4309ff2c.png 400w,
               /media/GA_1D_WFS_hufb84d618928132b13f235d1b5f732ff7_672866_c1e90efce0cb48c647b06ef8bed8af26.png 760w,
               /media/GA_1D_WFS_hufb84d618928132b13f235d1b5f732ff7_672866_1200x1200_fit_lanczos_3.png 1200w&#34;
               src=&#34;https://xiaodongwo.github.io/media/GA_1D_WFS_hufb84d618928132b13f235d1b5f732ff7_672866_5d0a98fd17bdd76708e6e4fb4309ff2c.png&#34;
               width=&#34;760&#34;
               height=&#34;583&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      &lt;strong&gt;Figure 1&lt;/strong&gt;. Wavefront Shaping by Genetic Algorithm
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-figure-2-numerical-demonstration-of-four-intelligent-algorithms-for-wavefront-shaping-a-genetic-algorithm-b-particle-swarm-optimization-c-beetle-antennae-search-and-d-sparrow-search-algorithm&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;screen reader text&#34; srcset=&#34;
               /media/FourIntelliAlgo_1D_IncidentLight_hu40db2b46e4329bc94c881778c7d15a35_853270_e3fa8cd16f7aebcf44dabb61f6508e20.png 400w,
               /media/FourIntelliAlgo_1D_IncidentLight_hu40db2b46e4329bc94c881778c7d15a35_853270_db19acdfbec91a1ba47a5d796cecfcbd.png 760w,
               /media/FourIntelliAlgo_1D_IncidentLight_hu40db2b46e4329bc94c881778c7d15a35_853270_1200x1200_fit_lanczos_3.png 1200w&#34;
               src=&#34;https://xiaodongwo.github.io/media/FourIntelliAlgo_1D_IncidentLight_hu40db2b46e4329bc94c881778c7d15a35_853270_e3fa8cd16f7aebcf44dabb61f6508e20.png&#34;
               width=&#34;760&#34;
               height=&#34;563&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      &lt;strong&gt;Figure 2&lt;/strong&gt;. Numerical Demonstration of Four Intelligent Algorithms for Wavefront Shaping. (a) Genetic Algorithm, (b) Particle Swarm Optimization, (c) Beetle Antennae Search, and (d) Sparrow Search Algorithm.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-figure-3-experimental-demonstration-of-genetic-algorithm-and-beetle-antennae-search-algorithm-for-wavefront-shaping-a-experimental-setup-b-focusing-by-genetic-algorithm-c-focusing-by-beetle-antennae-search-algorithm&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;screen reader text&#34; srcset=&#34;
               /media/ExperimentalFocusing_GA&amp;amp;BAS_hu679ae2a35b403cfd24481aa53436ef13_1693018_5fa1ead1ae3bae8fc3b8f5ac5f9680d0.png 400w,
               /media/ExperimentalFocusing_GA&amp;amp;BAS_hu679ae2a35b403cfd24481aa53436ef13_1693018_13c5f10d09497b343c823acbc30d946a.png 760w,
               /media/ExperimentalFocusing_GA&amp;amp;BAS_hu679ae2a35b403cfd24481aa53436ef13_1693018_1200x1200_fit_lanczos_3.png 1200w&#34;
               src=&#34;https://xiaodongwo.github.io/media/ExperimentalFocusing_GA&amp;amp;BAS_hu679ae2a35b403cfd24481aa53436ef13_1693018_5fa1ead1ae3bae8fc3b8f5ac5f9680d0.png&#34;
               width=&#34;745&#34;
               height=&#34;760&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      &lt;strong&gt;Figure 3&lt;/strong&gt;. Experimental Demonstration of Genetic Algorithm and Beetle Antennae Search Algorithm for Wavefront Shaping. (a) Experimental setup, (b) Focusing by genetic algorithm, (c) Focusing by beetle antennae search algorithm.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Note that in this project we aim to develop fluorescence imaging through scattering media using polymer dots (a type of fluorescence probe developed by group of &lt;a href=&#34;http://wulab.bme.sustech.edu.cn/team-member/changfeng-wu&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;em&gt;Changfeng Wu&lt;/em&gt;&lt;/a&gt;). And that&amp;rsquo;s why the numerical demonstration exploys a reflective optical scheme simulating fluorescence backpropagating through scatterig media, while in experimental section we are adopting a simpler transmissive optical scheme for algorithm validation.  For more details of the simulation demonstration, please refer to literatures&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Dayan Li, Sujit Kumar Sahoo, Huy Quoc Lam, Dong Wang, and Cuong Dang , &amp;ldquo;Non-invasive optical focusing inside strongly scattering media with linear fluorescence&amp;rdquo;, Appl. Phys. Lett. 116, 241104 (2020) &lt;a href=&#34;https://doi.org/10.1063/5.0004071&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1063/5.0004071&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</description>
    </item>
    
    <item>
      <title>Fluorescence-based Speckle Deconvolution Imaging</title>
      <link>https://xiaodongwo.github.io/projects/2st_project/</link>
      <pubDate>Wed, 08 Sep 2021 19:46:02 +0800</pubDate>
      <guid>https://xiaodongwo.github.io/projects/2st_project/</guid>
      <description>&lt;p&gt;Fast imaging through turbid media is of great interest in fields of astronomical observation and biological imaging. State-of-the-art approachs relies heavily on iterative optimization algorithms or prior charactirazation of scattering media,  hence impeding real time imaging scenerio. Memory-effect based methods expoit the inherent correlation of incident tilted light and thus can realize instant imaging thorugh scattering media.  Speckle deconvolution imaging through scattering media was proposed in 2016 for the first time and gains popularities these years in this field. To the best of our knowledge, this method has rarely been applied to fluorescence imaging in a reflective optical scheme. Here in this project we are showing some reconstruction results using polymer dots as fluorescence signal.&lt;/p&gt;
&lt;p&gt;The schematic for deconvolution imaging through scattering media is presented in Figure 1. The bottom-right corner represents the detailed derivation for PSF scaling, which can be found useful in subsequent extended-DOF and non-invasive imaging.
















&lt;figure  id=&#34;figure-figure-1-schematic-of-fluorescence-imaging-through-scattering-media-by-speckle-deconvolution&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;screen reader text&#34; srcset=&#34;
               /media/Schematic_hu7f4492a5ab451571dd432d474de2ddcf_1360457_eb894e75e72ef3f2047fc1ba5f1b5d29.png 400w,
               /media/Schematic_hu7f4492a5ab451571dd432d474de2ddcf_1360457_00b8bb10a062c8c92b1fc113dd4436b4.png 760w,
               /media/Schematic_hu7f4492a5ab451571dd432d474de2ddcf_1360457_1200x1200_fit_lanczos_3.png 1200w&#34;
               src=&#34;https://xiaodongwo.github.io/media/Schematic_hu7f4492a5ab451571dd432d474de2ddcf_1360457_eb894e75e72ef3f2047fc1ba5f1b5d29.png&#34;
               width=&#34;760&#34;
               height=&#34;498&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      &lt;strong&gt;Figure 1&lt;/strong&gt;. Schematic of fluorescence imaging through scattering media by speckle deconvolution
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;A home-built epi-fluorescence setup (a) for fast imaging through scattering media is presented, along with a custom-designed optical filter wheel (b) and polymer-dots based fluorescence sample (c). The system is operated and controled by LabVIEW software.
















&lt;figure  id=&#34;figure-figure-2-experimental-setup-of-fluorescence-imaging-through-scattering-media-by-speckle-deconvolution&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;screen reader text&#34; srcset=&#34;
               /media/Setup_hua3c117c02683fa3d7486d254f14b8669_3867803_86797fab9445caf02e7a826aed1a2ab2.png 400w,
               /media/Setup_hua3c117c02683fa3d7486d254f14b8669_3867803_1a6b37fa0fbb4b1e198d49885fc54fb6.png 760w,
               /media/Setup_hua3c117c02683fa3d7486d254f14b8669_3867803_1200x1200_fit_lanczos_3.png 1200w&#34;
               src=&#34;https://xiaodongwo.github.io/media/Setup_hua3c117c02683fa3d7486d254f14b8669_3867803_86797fab9445caf02e7a826aed1a2ab2.png&#34;
               width=&#34;760&#34;
               height=&#34;471&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      &lt;strong&gt;Figure 2&lt;/strong&gt;. Experimental setup of fluorescence imaging through scattering media by speckle deconvolution
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Speckle deconvolution imaging is demonstrated through the epi-fluorescence scattering imaging system. By measuring the PSF speckle (a) and object speckle (b) sequentially at the same depth, Wiener deconvolution manages to reconstruct the hidden object behind the thin scattering media with high fidiety, as shown in (d) the reconstruction and (c) the unknown object.
















&lt;figure  id=&#34;figure-figure-3-fluorescence-imaging-through-scattering-media-by-speckle-deconvolution&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;screen reader text&#34; srcset=&#34;
               /media/SpeckleDeconvo_hu140a324cefe85c824e331ed889362125_604885_40101a4aedfc6c7948962f239458dc99.png 400w,
               /media/SpeckleDeconvo_hu140a324cefe85c824e331ed889362125_604885_e21ae19275bdb1539143bd7a60fec86e.png 760w,
               /media/SpeckleDeconvo_hu140a324cefe85c824e331ed889362125_604885_1200x1200_fit_lanczos_3.png 1200w&#34;
               src=&#34;https://xiaodongwo.github.io/media/SpeckleDeconvo_hu140a324cefe85c824e331ed889362125_604885_40101a4aedfc6c7948962f239458dc99.png&#34;
               width=&#34;760&#34;
               height=&#34;596&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      &lt;strong&gt;Figure 3&lt;/strong&gt;. Fluorescence imaging through scattering media by speckle deconvolution
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;For more details, please check out my &lt;a href=&#34;https://www.sciencedirect.com/science/article/pii/S0143816622004432?dgcid=author&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;original paper&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Polymer-dots for STORM Imaging</title>
      <link>https://xiaodongwo.github.io/projects/3rd_project/</link>
      <pubDate>Wed, 08 Sep 2021 20:16:38 +0800</pubDate>
      <guid>https://xiaodongwo.github.io/projects/3rd_project/</guid>
      <description>&lt;p&gt;Fluorescent microscopy techniques are widely used in biological studies. However, the spatial resolution of fluorescent microscopy is restricted by the optical diffraction limit. In the past two decades, super-resolution imaging techniques with different principles have been invented to visualize biomolecules at nanometer scales. The development of nearly all these techniques is closely related to the advances in fluorescent probes.  In particular, the intrinsic properties of fluorescent probes constrain the optimal imaging performance of super-resolution nanoscopy techniques. Here for the first time we developed a novel class of semiconducting polymer dots that can operate in an optically switchable mode.&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-figure-1-polymer-dots-for-super-resolution-nanoscopy&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;screen reader text&#34; srcset=&#34;
               /media/FXF-pdots_hude0b9952417caf4ded36ad24773b5e32_1614581_ddf6c159e2f86f45d1ee85c5b8e06e77.png 400w,
               /media/FXF-pdots_hude0b9952417caf4ded36ad24773b5e32_1614581_b6760b0d5c9abb6b2ada2ac3eb069714.png 760w,
               /media/FXF-pdots_hude0b9952417caf4ded36ad24773b5e32_1614581_1200x1200_fit_lanczos_3.png 1200w&#34;
               src=&#34;https://xiaodongwo.github.io/media/FXF-pdots_hude0b9952417caf4ded36ad24773b5e32_1614581_ddf6c159e2f86f45d1ee85c5b8e06e77.png&#34;
               width=&#34;595&#34;
               height=&#34;760&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      &lt;strong&gt;Figure 1&lt;/strong&gt;. Polymer Dots for Super-resolution Nanoscopy
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;br/&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-figure-2-polymer-dots-for-super-resolution-nanoscopy&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;screen reader text&#34; srcset=&#34;
               /media/FXF-STORM_hu488180b06055f5e8692f03a8f3d014ee_1554972_1962643e8046af67207a7b86db3f9732.png 400w,
               /media/FXF-STORM_hu488180b06055f5e8692f03a8f3d014ee_1554972_853e1dd9dda7ad3205bc887aa278c38d.png 760w,
               /media/FXF-STORM_hu488180b06055f5e8692f03a8f3d014ee_1554972_1200x1200_fit_lanczos_3.png 1200w&#34;
               src=&#34;https://xiaodongwo.github.io/media/FXF-STORM_hu488180b06055f5e8692f03a8f3d014ee_1554972_1962643e8046af67207a7b86db3f9732.png&#34;
               width=&#34;760&#34;
               height=&#34;634&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      &lt;strong&gt;Figure 2&lt;/strong&gt;. Polymer Dots for Super-resolution Nanoscopy
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;&lt;br/&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Image-guided Wavefront Shaping</title>
      <link>https://xiaodongwo.github.io/projects/4th_project/</link>
      <pubDate>Wed, 08 Sep 2021 20:24:22 +0800</pubDate>
      <guid>https://xiaodongwo.github.io/projects/4th_project/</guid>
      <description>&lt;p&gt;Wavefront shaping unlocked many exciting applications related to imaging through scattering media. However, they usually require to have some feedback from the object to observe, typically a guide-star generated by physically labeling the sample or by using ultrasound (that reduced the resolution). Other computer-based approaches recently developed relied on the memory-effect, which drastically limits the field of view, or requires a coherent illumination. In the present paper, T. Yeminy and O. Katz present a very simple approach that allows the reconstruction of an object hidden behind a scattering medium under incoherent illumination. It uses wavefront shaping of the scattered light together with an optimization procedure based on some assumptions about the object. Here we implemented the numerical simulation part in this work. It&amp;rsquo;s kind of intersting concept, isn&amp;rsquo;t it?&lt;/p&gt;
&lt;p&gt;This is just for demonstration and personal interest.  For more details, please refer to the original literature&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-figure-1-numerical-simulation-of-image-guided-wavefront-shaping&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;screen reader text&#34; srcset=&#34;
               /media/Image-guided_wavefront_shaping_hudbb9a705a0dfe3f6f005cac7d62ad919_751819_019e61e16ebbd410e59adb1b1f4c4b22.png 400w,
               /media/Image-guided_wavefront_shaping_hudbb9a705a0dfe3f6f005cac7d62ad919_751819_46731f4e29d757cf14aeba0980e3c6bf.png 760w,
               /media/Image-guided_wavefront_shaping_hudbb9a705a0dfe3f6f005cac7d62ad919_751819_1200x1200_fit_lanczos_3.png 1200w&#34;
               src=&#34;https://xiaodongwo.github.io/media/Image-guided_wavefront_shaping_hudbb9a705a0dfe3f6f005cac7d62ad919_751819_019e61e16ebbd410e59adb1b1f4c4b22.png&#34;
               width=&#34;760&#34;
               height=&#34;425&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      &lt;strong&gt;Figure 1&lt;/strong&gt;. Numerical Simulation of Image-guided Wavefront Shaping
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Yeminy, Tomer &amp;amp; Katz, Ori. (2021). Guidestar-free image-guided wavefront shaping. Science Advances. 7. eabf5364. 10.1126/sciadv.abf5364.&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</description>
    </item>
    
    <item>
      <title>Optical coherence tomography‚Äîin situ and high speed 3D imaging for laser materials processing</title>
      <link>https://xiaodongwo.github.io/publication/light-2022/</link>
      <pubDate>Sun, 25 Dec 2022 00:00:00 +0000</pubDate>
      <guid>https://xiaodongwo.github.io/publication/light-2022/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Spectra-separated depth-of-field extended fluorescence imaging through scattering media using speckle deconvolution</title>
      <link>https://xiaodongwo.github.io/publication/ole-20221225/</link>
      <pubDate>Sun, 25 Dec 2022 00:00:00 +0000</pubDate>
      <guid>https://xiaodongwo.github.io/publication/ole-20221225/</guid>
      <description>&lt;p&gt;Supplementary notes can be added here, including &lt;a href=&#34;https://view.officeapps.live.com/op/view.aspx?src=https%3A%2F%2Fars.els-cdn.com%2Fcontent%2Fimage%2F1-s2.0-S0143816622004432-mmc1.docx&amp;amp;wdOrigin=BROWSELINK&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;instrumentaion and images&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Near-Infrared Optical Transducer for Dynamic Imaging of Cerebrospinal Fluid Glucose in Brain Tumor</title>
      <link>https://xiaodongwo.github.io/publication/ac-2022/</link>
      <pubDate>Tue, 25 Oct 2022 00:00:00 +0000</pubDate>
      <guid>https://xiaodongwo.github.io/publication/ac-2022/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Academic Blogging</title>
      <link>https://xiaodongwo.github.io/post/academicblogging/</link>
      <pubDate>Tue, 21 Jun 2022 21:41:59 +0800</pubDate>
      <guid>https://xiaodongwo.github.io/post/academicblogging/</guid>
      <description>&lt;h2 id=&#34;oct&#34;&gt;OCT&lt;/h2&gt;
&lt;p&gt;Optical coherence tomography (OCT) is an optical instrument that can perform cross-sectional image of biological tissue within less than 10 micro axial resolution using broadband light waves (830nm) near infrared light. The beam is then split into two beams (reference beam and probe beam) by beam splitter. Probe beam reach to the target tissue while reference beam reach to the reference mirror at a known distance. The echo time delay of light reflected from various layer of target tissue is compared with the echo time delay of light reflected from the reference mirror. The interference is measured by a photodetector which produce a range of time delays for comparison. There are two main OCT technologies, time-domain OCT (TD-OCT) and Fourier-domain OCT (FD-OCT). In a TD-OCT measurement the light echoes are
detected sequentially by the step-movement of a reference mirror, while in FD-OCT the light echoes come at the same time from all axial depths and are detected as modulations in the source spectrum with all the spectral components captured simultaneously. FD-OCT provides faster imaging speed due to its non-scanning fashion compared with TD-OCT.&lt;/p&gt;
&lt;p&gt;Conventionally, both the time-domain OCT (TD-OCT) and Fourier-domain OCT (FD-OCT) perform beam steering to scan the lateral plane (x; y). This scanning process assumes a single photo-diode to capture the light each time from a single spatial point. One natural question is that &amp;ldquo;can we capture the whole spatial points in parallel?&amp;rdquo;. Full-field or wide-field OCT is thereafter is invented to address this problem.&lt;/p&gt;
&lt;p&gt;Will be updated soon&amp;hellip;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>News</title>
      <link>https://xiaodongwo.github.io/post/my-gallery/</link>
      <pubDate>Thu, 16 Sep 2021 22:43:11 +0800</pubDate>
      <guid>https://xiaodongwo.github.io/post/my-gallery/</guid>
      <description>&lt;p&gt;I recently obtained my Master&amp;rsquo;s degree with Master Thesis of &amp;ldquo;RESEARCH ON FOCUSING AND DECONVOLUTION IMAGING ALGORITHMS THROUGH STATIC SCATTERING MEDIA&amp;rdquo;!
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;screen reader text&#34; srcset=&#34;
               /media/MasterGradu_hufeb3366574d556c5c246e646145af218_1489779_3c22effaf0052a81268cae22f3db33be.jpg 400w,
               /media/MasterGradu_hufeb3366574d556c5c246e646145af218_1489779_f71caf398c15b5839a464f224568935f.jpg 760w,
               /media/MasterGradu_hufeb3366574d556c5c246e646145af218_1489779_1200x1200_fit_q75_lanczos.jpg 1200w&#34;
               src=&#34;https://xiaodongwo.github.io/media/MasterGradu_hufeb3366574d556c5c246e646145af218_1489779_3c22effaf0052a81268cae22f3db33be.jpg&#34;
               width=&#34;760&#34;
               height=&#34;570&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Group photos in SUSTECH!
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;screen reader text&#34; srcset=&#34;
               /media/a_hu853a5b38495db70d1077e9337cfac00d_816675_d8761e914403fec8e053da2361848776.jpg 400w,
               /media/a_hu853a5b38495db70d1077e9337cfac00d_816675_8ded51c95213cf69eacbe3e077331117.jpg 760w,
               /media/a_hu853a5b38495db70d1077e9337cfac00d_816675_1200x1200_fit_q75_lanczos.jpg 1200w&#34;
               src=&#34;https://xiaodongwo.github.io/media/a_hu853a5b38495db70d1077e9337cfac00d_816675_d8761e914403fec8e053da2361848776.jpg&#34;
               width=&#34;760&#34;
               height=&#34;507&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Group photos in CUST!
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;screen reader text&#34; srcset=&#34;
               /media/b_hu2cdc6fb687aaa0588a9a6befa2f69f65_898922_0e5b5af7e9ed26d36ede49f5b6f0678d.jpg 400w,
               /media/b_hu2cdc6fb687aaa0588a9a6befa2f69f65_898922_fb2fa90b337988a4f1b148a6fa6c13bf.jpg 760w,
               /media/b_hu2cdc6fb687aaa0588a9a6befa2f69f65_898922_1200x1200_fit_q75_lanczos.jpg 1200w&#34;
               src=&#34;https://xiaodongwo.github.io/media/b_hu2cdc6fb687aaa0588a9a6befa2f69f65_898922_0e5b5af7e9ed26d36ede49f5b6f0678d.jpg&#34;
               width=&#34;760&#34;
               height=&#34;570&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Magic workshop!
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;screen reader text&#34; srcset=&#34;
               /media/c_hu4c053b446906fb91f554ec4b2e443c71_362542_77e0c17485148b6db7700d93ca48f099.jpeg 400w,
               /media/c_hu4c053b446906fb91f554ec4b2e443c71_362542_303b2c10e80b9852ee6c753b03cbc341.jpeg 760w,
               /media/c_hu4c053b446906fb91f554ec4b2e443c71_362542_1200x1200_fit_q75_lanczos.jpeg 1200w&#34;
               src=&#34;https://xiaodongwo.github.io/media/c_hu4c053b446906fb91f554ec4b2e443c71_362542_77e0c17485148b6db7700d93ca48f099.jpeg&#34;
               width=&#34;760&#34;
               height=&#34;570&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Friends in CUST!
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;screen reader text&#34; srcset=&#34;
               /media/d_hu95352d27dcb59c78d3a5ecbe4f9eaf5c_189860_368c12e194103a37fd836d1487304563.jpeg 400w,
               /media/d_hu95352d27dcb59c78d3a5ecbe4f9eaf5c_189860_d10b492b951043ca51d884ec74a85dbb.jpeg 760w,
               /media/d_hu95352d27dcb59c78d3a5ecbe4f9eaf5c_189860_1200x1200_fit_q75_lanczos.jpeg 1200w&#34;
               src=&#34;https://xiaodongwo.github.io/media/d_hu95352d27dcb59c78d3a5ecbe4f9eaf5c_189860_368c12e194103a37fd836d1487304563.jpeg&#34;
               width=&#34;760&#34;
               height=&#34;570&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Volunteering in International OSA Network of StudentsÔºÅ
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;screen reader text&#34; srcset=&#34;
               /media/e_hue32584e15a30e0453fa738bd6ac02337_71594_c44a5ffab1a6220a9ba754958d5030fb.jpeg 400w,
               /media/e_hue32584e15a30e0453fa738bd6ac02337_71594_2a34df36df6a0279974af248631bc2dd.jpeg 760w,
               /media/e_hue32584e15a30e0453fa738bd6ac02337_71594_1200x1200_fit_q75_lanczos.jpeg 1200w&#34;
               src=&#34;https://xiaodongwo.github.io/media/e_hue32584e15a30e0453fa738bd6ac02337_71594_c44a5ffab1a6220a9ba754958d5030fb.jpeg&#34;
               width=&#34;760&#34;
               height=&#34;506&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;I obtained my bachelor&amp;rsquo;s degree with Bachelor Thesis of &amp;ldquo;Design of Asymmetric Integrated Waveguide M-Z Interferometer&amp;rdquo;!
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;screen reader text&#34; srcset=&#34;
               /media/f_hu45a722346b763ee633a9623724651e76_250411_60341ed39fbadf9fdad4ffabb6225269.jpeg 400w,
               /media/f_hu45a722346b763ee633a9623724651e76_250411_49459c871012f6d4e62a8d1a293f9455.jpeg 760w,
               /media/f_hu45a722346b763ee633a9623724651e76_250411_1200x1200_fit_q75_lanczos.jpeg 1200w&#34;
               src=&#34;https://xiaodongwo.github.io/media/f_hu45a722346b763ee633a9623724651e76_250411_60341ed39fbadf9fdad4ffabb6225269.jpeg&#34;
               width=&#34;760&#34;
               height=&#34;570&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Practicing sleight of hands!









  





&lt;video controls  &gt;
  &lt;source src=&#34;https://xiaodongwo.github.io/media/Wechat.mp4&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>10ÂÄçÂèåÁõÆÊúõËøúÈïúËÆæËÆ°</title>
      <link>https://xiaodongwo.github.io/projects/5th_project/</link>
      <pubDate>Thu, 16 Sep 2021 21:20:19 +0800</pubDate>
      <guid>https://xiaodongwo.github.io/projects/5th_project/</guid>
      <description>&lt;br/&gt;
&gt;&gt; È°πÁõÆÊ¶ÇËø∞Ôºö
&lt;br/&gt;Ê†πÊçÆÊâÄÁªôÂäüËÉΩÂèÇÊï∞ËÆæËÆ°ÂÖ´ÂÄçÂèåÁõÆÊúõËøúÈïúÔºåÂàÜÊûêÂÖâÂ≠¶Á≥ªÁªüÂÉèÂ∑ÆÔºåËÆæËÆ°Á≤æÂØÜ‰ª™Âô®ÁªìÊûÑ„ÄÇ
&lt;br/&gt;
&lt;br/&gt;
&gt;&gt; È°πÁõÆÂÜÖÂÆπÔºö
&lt;br/&gt;1.ËøêÁî®Âá†‰ΩïÂÖâÂ≠¶ÊâÄÂ≠¶Áü•ËØÜÔºåËÆ°ÁÆóÂÖâÂ≠¶Á≥ªÁªüÂÖ≥ÈîÆÊÄßÂèÇÊï∞ÔºåËøêÁî®ÂÉèÂ∑ÆÁêÜËÆ∫Áü•ËØÜÂíåËÆ°ÁÆóÊú∫ËøõË°åÂèÇÊï∞‰ºòÂåñ‰ª•ÂáèÂ∞èÂÉèÂ∑ÆÔºåÁ°ÆÂÆöÊúÄÁªàÂÖâÂ≠¶Á≥ªÁªüÔºõ
&lt;br/&gt;2.ËøêÁî®Á≤æÂØÜÊú∫Ê¢∞ËÆæËÆ°ÂíåËØØÂ∑ÆÂÖ¨Â∑ÆÁêÜËÆ∫ÊâÄÂ≠¶Áü•ËØÜÔºåÈÄâÂÆöÂêÑ‰∏™Èõ∂‰ª∂ÔºåÁ°ÆÂÆöÂÖâÊú∫ÁªìÊûÑÔºåÂ¶ÇÁî®ÂéãÂúàÂéãÁ¥ßÂêÑ‰∏™ÈÄèÈïúÁ≠âÔºàÂ∞∫ÂØ∏ÔºåÂÖ¨Â∑ÆËØØÂ∑ÆÁ≠âÔºâÔºõ
&lt;br/&gt;3.ËøêÁî®CADÂíåSOLIDWORKSËÆæËÆ°Èõ∂‰ª∂ÁªìÊûÑÂèäÊúÄÁªàË£ÖÈÖçÂõæÔºåËøõË°åÁ≠îËæ©„ÄÇ
&lt;br/&gt;&lt;br/&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-figure-1-ÂèåÁõÆÊúõËøúÈïúÈÉ®ÂàÜÈõ∂‰ª∂ËÆæËÆ°ÂèäÊúÄÁªàÁªìÊûÑÂõæ&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;screen reader text&#34; srcset=&#34;
               /media/bicular_hu534aec16f87b6688786ed0acb542a730_1400213_a1d545056e89a3449b778c38b78cc9c4.png 400w,
               /media/bicular_hu534aec16f87b6688786ed0acb542a730_1400213_00ed6d0faa5db757f44aea34d6f1f0e4.png 760w,
               /media/bicular_hu534aec16f87b6688786ed0acb542a730_1400213_1200x1200_fit_lanczos_3.png 1200w&#34;
               src=&#34;https://xiaodongwo.github.io/media/bicular_hu534aec16f87b6688786ed0acb542a730_1400213_a1d545056e89a3449b778c38b78cc9c4.png&#34;
               width=&#34;640&#34;
               height=&#34;760&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      &lt;br/&gt; &lt;strong&gt;Figure 1&lt;/strong&gt;. ÂèåÁõÆÊúõËøúÈïúÈÉ®ÂàÜÈõ∂‰ª∂ËÆæËÆ°ÂèäÊúÄÁªàÁªìÊûÑÂõæ
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;br/&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-figure-2-‰∏ùÊùÜÁªìÊûÑË£ÖÈÖçÂõæ&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;screen reader text&#34; srcset=&#34;
               /media/CAD_hu0063cb27bef41183307c1a010e676363_90403_2ec888cfde8d0328ca50bfefefc62b78.png 400w,
               /media/CAD_hu0063cb27bef41183307c1a010e676363_90403_8f530f50d7fe0768d19f80e25754c987.png 760w,
               /media/CAD_hu0063cb27bef41183307c1a010e676363_90403_1200x1200_fit_lanczos_3.png 1200w&#34;
               src=&#34;https://xiaodongwo.github.io/media/CAD_hu0063cb27bef41183307c1a010e676363_90403_2ec888cfde8d0328ca50bfefefc62b78.png&#34;
               width=&#34;760&#34;
               height=&#34;393&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      &lt;br/&gt; &lt;strong&gt;Figure 2&lt;/strong&gt;. ‰∏ùÊùÜÁªìÊûÑË£ÖÈÖçÂõæ
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Tuturials for academic website building with Hugo and Github</title>
      <link>https://xiaodongwo.github.io/post/getting-started/</link>
      <pubDate>Sun, 13 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://xiaodongwo.github.io/post/getting-started/</guid>
      <description>&lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;The Wowchemy website builder for Hugo, along with its starter templates, is designed for professional creators, educators, and teams/organizations - although it can be used to create any kind of site&lt;/li&gt;
&lt;li&gt;The template can be modified and customised to suit your needs. It&amp;rsquo;s a good platform for anyone looking to take control of their data and online identity whilst having the convenience to start off with a &lt;strong&gt;no-code solution (write in Markdown and customize with YAML parameters)&lt;/strong&gt; and having &lt;strong&gt;flexibility to later add even deeper personalization with HTML and CSS&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;You can work with all your favourite tools and apps with hundreds of plugins and integrations to speed up your workflows, interact with your readers, and much more&lt;/li&gt;
&lt;/ol&gt;














&lt;figure  id=&#34;figure-the-template-is-mobile-first-with-a-responsive-design-to-ensure-that-your-site-looks-stunning-on-every-device&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://raw.githubusercontent.com/wowchemy/wowchemy-hugo-modules/master/academic.png&#34; alt=&#34;The template is mobile first with a responsive design to ensure that your site looks stunning on every device.&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      The template is mobile first with a responsive design to ensure that your site looks stunning on every device.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;h2 id=&#34;get-started&#34;&gt;Get Started&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;üëâ &lt;a href=&#34;https://wowchemy.com/templates/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;Create a new site&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;üìö &lt;a href=&#34;https://wowchemy.com/docs/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;Personalize your site&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;üí¨ &lt;a href=&#34;https://discord.gg/z8wNYzb&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Chat with the &lt;strong&gt;Wowchemy community&lt;/strong&gt;&lt;/a&gt; or &lt;a href=&#34;https://discourse.gohugo.io&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;Hugo community&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;üê¶ Twitter: &lt;a href=&#34;https://twitter.com/wowchemy&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;@wowchemy&lt;/a&gt; &lt;a href=&#34;https://twitter.com/GeorgeCushen&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;@GeorgeCushen&lt;/a&gt; &lt;a href=&#34;https://twitter.com/search?q=%28%23MadeWithWowchemy%20OR%20%23MadeWithAcademic%29&amp;amp;src=typed_query&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;#MadeWithWowchemy&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;üí° &lt;a href=&#34;https://github.com/wowchemy/wowchemy-hugo-modules/issues&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Request a &lt;strong&gt;feature&lt;/strong&gt; or report a &lt;strong&gt;bug&lt;/strong&gt; for &lt;em&gt;Wowchemy&lt;/em&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;‚¨ÜÔ∏è &lt;strong&gt;Updating Wowchemy?&lt;/strong&gt; View the &lt;a href=&#34;https://wowchemy.com/docs/guide/update/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Update Guide&lt;/a&gt; and &lt;a href=&#34;https://wowchemy.com/updates/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Release Notes&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;crowd-funded-open-source-software&#34;&gt;Crowd-funded open-source software&lt;/h2&gt;
&lt;p&gt;To help us develop this template and software sustainably under the MIT license, we ask all individuals and businesses that use it to help support its ongoing maintenance and development via sponsorship.&lt;/p&gt;
&lt;h3 id=&#34;-click-here-to-become-a-sponsor-and-help-support-wowchemys-future-httpswowchemycomplans&#34;&gt;&lt;a href=&#34;https://wowchemy.com/plans/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;‚ù§Ô∏è Click here to become a sponsor and help support Wowchemy&amp;rsquo;s future ‚ù§Ô∏è&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;As a token of appreciation for sponsoring, you can &lt;strong&gt;unlock &lt;a href=&#34;https://wowchemy.com/plans/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;these&lt;/a&gt; awesome rewards and extra features ü¶Ñ‚ú®&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&#34;ecosystem&#34;&gt;Ecosystem&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/wowchemy/hugo-academic-cli&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Hugo Academic CLI&lt;/a&gt;:&lt;/strong&gt; Automatically import publications from BibTeX&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;inspiration&#34;&gt;Inspiration&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://academic-demo.netlify.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Check out the latest &lt;strong&gt;demo&lt;/strong&gt;&lt;/a&gt; of what you&amp;rsquo;ll get in less than 10 minutes, or &lt;a href=&#34;https://wowchemy.com/user-stories/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;view the &lt;strong&gt;showcase&lt;/strong&gt;&lt;/a&gt; of personal, project, and business sites.&lt;/p&gt;
&lt;h2 id=&#34;features&#34;&gt;Features&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Page builder&lt;/strong&gt; - Create &lt;em&gt;anything&lt;/em&gt; with &lt;a href=&#34;https://wowchemy.com/docs/page-builder/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;widgets&lt;/strong&gt;&lt;/a&gt; and &lt;a href=&#34;https://wowchemy.com/docs/writing-markdown-latex/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;elements&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Edit any type of content&lt;/strong&gt; - Blog posts, publications, talks, slides, projects, and more!&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Create content&lt;/strong&gt; in &lt;a href=&#34;https://wowchemy.com/docs/writing-markdown-latex/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;Markdown&lt;/strong&gt;&lt;/a&gt;, &lt;a href=&#34;https://wowchemy.com/docs/import/jupyter/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;Jupyter&lt;/strong&gt;&lt;/a&gt;, or &lt;a href=&#34;https://wowchemy.com/docs/install-locally/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;RStudio&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Plugin System&lt;/strong&gt; - Fully customizable &lt;a href=&#34;https://wowchemy.com/docs/customization/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;color&lt;/strong&gt; and &lt;strong&gt;font themes&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Display Code and Math&lt;/strong&gt; - Code highlighting and &lt;a href=&#34;https://en.wikibooks.org/wiki/LaTeX/Mathematics&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;LaTeX math&lt;/a&gt; supported&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Integrations&lt;/strong&gt; - &lt;a href=&#34;https://analytics.google.com&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Google Analytics&lt;/a&gt;, &lt;a href=&#34;https://disqus.com&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Disqus commenting&lt;/a&gt;, Maps, Contact Forms, and more!&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Beautiful Site&lt;/strong&gt; - Simple and refreshing one page design&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Industry-Leading SEO&lt;/strong&gt; - Help get your website found on search engines and social media&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Media Galleries&lt;/strong&gt; - Display your images and videos with captions in a customizable gallery&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Mobile Friendly&lt;/strong&gt; - Look amazing on every screen with a mobile friendly version of your site&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Multi-language&lt;/strong&gt; - 34+ language packs including English, ‰∏≠Êñá, and Portugu√™s&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Multi-user&lt;/strong&gt; - Each author gets their own profile page&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Privacy Pack&lt;/strong&gt; - Assists with GDPR&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Stand Out&lt;/strong&gt; - Bring your site to life with animation, parallax backgrounds, and scroll effects&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;One-Click Deployment&lt;/strong&gt; - No servers. No databases. Only files.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;themes&#34;&gt;Themes&lt;/h2&gt;
&lt;p&gt;Wowchemy and its templates come with &lt;strong&gt;automatic day (light) and night (dark) mode&lt;/strong&gt; built-in. Alternatively, visitors can choose their preferred mode - click the moon icon in the top right of the &lt;a href=&#34;https://academic-demo.netlify.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Demo&lt;/a&gt; to see it in action! Day/night mode can also be disabled by the site admin in &lt;code&gt;params.toml&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://wowchemy.com/docs/customization&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Choose a stunning &lt;strong&gt;theme&lt;/strong&gt; and &lt;strong&gt;font&lt;/strong&gt;&lt;/a&gt; for your site. Themes are fully customizable.&lt;/p&gt;
&lt;h2 id=&#34;license&#34;&gt;License&lt;/h2&gt;
&lt;p&gt;Copyright 2016-present &lt;a href=&#34;https://georgecushen.com&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;George Cushen&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Released under the &lt;a href=&#34;https://github.com/wowchemy/wowchemy-hugo-modules/blob/master/LICENSE.md&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;MIT&lt;/a&gt; license.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Fluorescent Bioconjugates for Super-Resolution Optical Nanoscopy</title>
      <link>https://xiaodongwo.github.io/publication/bc-2020/</link>
      <pubDate>Wed, 01 Jul 2020 00:00:00 +0000</pubDate>
      <guid>https://xiaodongwo.github.io/publication/bc-2020/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Slides</title>
      <link>https://xiaodongwo.github.io/slides/example/</link>
      <pubDate>Tue, 05 Feb 2019 00:00:00 +0000</pubDate>
      <guid>https://xiaodongwo.github.io/slides/example/</guid>
      <description>&lt;h1 id=&#34;create-slides-in-markdown-with-wowchemy&#34;&gt;Create slides in Markdown with Wowchemy&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://wowchemy.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Wowchemy&lt;/a&gt; | &lt;a href=&#34;https://owchemy.com/docs/managing-content/#create-slides&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Documentation&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;features&#34;&gt;Features&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Efficiently write slides in Markdown&lt;/li&gt;
&lt;li&gt;3-in-1: Create, Present, and Publish your slides&lt;/li&gt;
&lt;li&gt;Supports speaker notes&lt;/li&gt;
&lt;li&gt;Mobile friendly slides&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;controls&#34;&gt;Controls&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Next: &lt;code&gt;Right Arrow&lt;/code&gt; or &lt;code&gt;Space&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Previous: &lt;code&gt;Left Arrow&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Start: &lt;code&gt;Home&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Finish: &lt;code&gt;End&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Overview: &lt;code&gt;Esc&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Speaker notes: &lt;code&gt;S&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Fullscreen: &lt;code&gt;F&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Zoom: &lt;code&gt;Alt + Click&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/hakimel/reveal.js#pdf-export&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PDF Export&lt;/a&gt;: &lt;code&gt;E&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;code-highlighting&#34;&gt;Code Highlighting&lt;/h2&gt;
&lt;p&gt;Inline code: &lt;code&gt;variable&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Code block:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;porridge = &amp;quot;blueberry&amp;quot;
if porridge == &amp;quot;blueberry&amp;quot;:
    print(&amp;quot;Eating...&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;math&#34;&gt;Math&lt;/h2&gt;
&lt;p&gt;In-line math: $x + y = z$&lt;/p&gt;
&lt;p&gt;Block math:&lt;/p&gt;
&lt;p&gt;$$
f\left( x \right) = ;\frac{{2\left( {x + 4} \right)\left( {x - 4} \right)}}{{\left( {x + 4} \right)\left( {x + 1} \right)}}
$$&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;fragments&#34;&gt;Fragments&lt;/h2&gt;
&lt;p&gt;Make content appear incrementally&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{{% fragment %}} One {{% /fragment %}}
{{% fragment %}} **Two** {{% /fragment %}}
{{% fragment %}} Three {{% /fragment %}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Press &lt;code&gt;Space&lt;/code&gt; to play!&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;fragment &#34; &gt;
One
&lt;/span&gt;
&lt;span class=&#34;fragment &#34; &gt;
&lt;strong&gt;Two&lt;/strong&gt;
&lt;/span&gt;
&lt;span class=&#34;fragment &#34; &gt;
Three
&lt;/span&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;A fragment can accept two optional parameters:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;class&lt;/code&gt;: use a custom style (requires definition in custom CSS)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;weight&lt;/code&gt;: sets the order in which a fragment appears&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;speaker-notes&#34;&gt;Speaker Notes&lt;/h2&gt;
&lt;p&gt;Add speaker notes to your presentation&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;{{% speaker_note %}}
- Only the speaker can read these notes
- Press `S` key to view
{{% /speaker_note %}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Press the &lt;code&gt;S&lt;/code&gt; key to view the speaker notes!&lt;/p&gt;
&lt;aside class=&#34;notes&#34;&gt;
  &lt;ul&gt;
&lt;li&gt;Only the speaker can read these notes&lt;/li&gt;
&lt;li&gt;Press &lt;code&gt;S&lt;/code&gt; key to view&lt;/li&gt;
&lt;/ul&gt;

&lt;/aside&gt;
&lt;hr&gt;
&lt;h2 id=&#34;themes&#34;&gt;Themes&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;black: Black background, white text, blue links (default)&lt;/li&gt;
&lt;li&gt;white: White background, black text, blue links&lt;/li&gt;
&lt;li&gt;league: Gray background, white text, blue links&lt;/li&gt;
&lt;li&gt;beige: Beige background, dark text, brown links&lt;/li&gt;
&lt;li&gt;sky: Blue background, thin dark text, blue links&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;ul&gt;
&lt;li&gt;night: Black background, thick white text, orange links&lt;/li&gt;
&lt;li&gt;serif: Cappuccino background, gray text, brown links&lt;/li&gt;
&lt;li&gt;simple: White background, black text, blue links&lt;/li&gt;
&lt;li&gt;solarized: Cream-colored background, dark green text, blue links&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;

&lt;section data-noprocess data-shortcode-slide
  
      
      data-background-image=&#34;/media/boards.jpg&#34;
  &gt;

&lt;h2 id=&#34;custom-slide&#34;&gt;Custom Slide&lt;/h2&gt;
&lt;p&gt;Customize the slide style and background&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;{{&amp;lt; slide background-image=&amp;quot;/media/boards.jpg&amp;quot; &amp;gt;}}
{{&amp;lt; slide background-color=&amp;quot;#0000FF&amp;quot; &amp;gt;}}
{{&amp;lt; slide class=&amp;quot;my-style&amp;quot; &amp;gt;}}
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;custom-css-example&#34;&gt;Custom CSS Example&lt;/h2&gt;
&lt;p&gt;Let&amp;rsquo;s make headers navy colored.&lt;/p&gt;
&lt;p&gt;Create &lt;code&gt;assets/css/reveal_custom.css&lt;/code&gt; with:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-css&#34;&gt;.reveal section h1,
.reveal section h2,
.reveal section h3 {
  color: navy;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h1 id=&#34;questions&#34;&gt;Questions?&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/wowchemy/wowchemy-hugo-modules/discussions&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ask&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://wowchemy.com/docs/managing-content/#create-slides&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Documentation&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>An example conference paper</title>
      <link>https://xiaodongwo.github.io/publication/example/</link>
      <pubDate>Mon, 01 Jul 2013 00:00:00 +0000</pubDate>
      <guid>https://xiaodongwo.github.io/publication/example/</guid>
      <description>&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Create your slides in Markdown - click the &lt;em&gt;Slides&lt;/em&gt; button to check out the example.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Supplementary notes can be added here, including &lt;a href=&#34;https://wowchemy.com/docs/writing-markdown-latex/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;code, math, and images&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>https://xiaodongwo.github.io/admin/config.yml</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://xiaodongwo.github.io/admin/config.yml</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
